{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AhmedFarrukh/DeepLearning-EdgeComputing/blob/main/notebooks/MeasuringInferenceTimes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrF-tC2TOA5x"
   },
   "source": [
    "In this notebook, the inference times and memory footprint of the original and quantized versions of 7 popular Convolutional Neural Networks are measured and compared.\n",
    "\n",
    "The CNN models are: MobileNet, InceptionV3, Resnet50, ResNet101, ResNet152, VGG16, VGG19.\n",
    "\n",
    "The quantized models were created by applying [Post-training Dynamic Range Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).\n",
    "\n",
    "Both the original models, and their quantized versions, are of tflite format, and were uploaded to [Google Drive](https://drive.google.com/drive/folders/1OcJ9ceYg6ZWFJ4QMR0zznsw0KVeHPa4h?usp=drive_link).\n",
    "\n",
    "The benchmarking of models is achieved by using the official [TFlite benchmark](https://www.tensorflow.org/lite/performance/measurement) which measures the following metrics:\n",
    "*   Initialization time\n",
    "*   Inference time of warmup state\n",
    "*   Inference time of steady state\n",
    "*   Memory usage during initialization time\n",
    "*   Overall memory usage\n",
    "\n",
    "The benchmark generates a series of random inputs, runs the models and aggregates the results to report the aforementioned metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ToA8HeyjN7qQ"
   },
   "outputs": [],
   "source": [
    "modelNames = [\"MobileNet\", \"InceptionV3\", \"ResNet50\", \"ResNet101\", \"ResNet152\", \"VGG16\", \"VGG19\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZVUtaESAFA6"
   },
   "source": [
    "We can download the models from the Google Drive using gdown. If you want to download your own set of models, you can modify the google drive link below. In this case, we download the models to the /root/tflite_models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jvAZKLKwAFdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cc/DeepLearning-EdgeComputing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 190OgRXUl3gZfxLqqayk6ebW0Eyu6zuii InceptionV3_quant.tflite\n",
      "Processing file 1qHe6rtJgsnS_JMa-XK5160DHU2wICrD_ InceptionV3.tflite\n",
      "Processing file 12uKNdkCGtPnKr5nYDOG8RiU2r8cHlP5U MobileNet_quant.tflite\n",
      "Processing file 1pjsdyJdO7JKz1Qc1q3Hypd_JSKSTCrO6 MobileNet.tflite\n",
      "Processing file 1-3jO54_5e6E22wG-P_Km-SHMxLlUnT_r ResNet50_quant.tflite\n",
      "Processing file 1cl1g9EN307xLkxH-12IVJ76x-kobeMhf ResNet50.tflite\n",
      "Processing file 1oCjM_VWXrAVToRwuUFgW1bupBpmc7Rwx ResNet101_quant.tflite\n",
      "Processing file 1yImWscZUsOANKwV15WIN77o7Q2Yrkc14 ResNet101.tflite\n",
      "Processing file 1824S3uNOro0WBlccpflEJhXzGR8k7L5w ResNet152_quant.tflite\n",
      "Processing file 1JwfKL79O75XiamF5iEqGkUSt9LYygwS3 ResNet152.tflite\n",
      "Processing file 1m-RI9IV3vIuiHJ-BoHc4XnPn0fewJzGs VGG16_quant.tflite\n",
      "Processing file 1XywqHW8wmqkfTw6cjo7xlnYaTlr9AbwE VGG16.tflite\n",
      "Processing file 1Jo-SqyPZvCG8p2Cvpq1tNPhd3LavQ24_ VGG19_quant.tflite\n",
      "Processing file 1sEfBpOdcw-LQAl24Y0SMH4fVWoyCCBki VGG19.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=190OgRXUl3gZfxLqqayk6ebW0Eyu6zuii\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/InceptionV3_quant.tflite\n",
      "100%|██████████| 24.1M/24.1M [00:00<00:00, 70.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qHe6rtJgsnS_JMa-XK5160DHU2wICrD_\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/InceptionV3.tflite\n",
      "100%|██████████| 95.3M/95.3M [00:02<00:00, 46.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12uKNdkCGtPnKr5nYDOG8RiU2r8cHlP5U\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet_quant.tflite\n",
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 23.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pjsdyJdO7JKz1Qc1q3Hypd_JSKSTCrO6\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet.tflite\n",
      "100%|██████████| 16.9M/16.9M [00:00<00:00, 49.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-3jO54_5e6E22wG-P_Km-SHMxLlUnT_r\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet50_quant.tflite\n",
      "100%|██████████| 26.0M/26.0M [00:00<00:00, 42.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1cl1g9EN307xLkxH-12IVJ76x-kobeMhf\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet50.tflite\n",
      "100%|██████████| 102M/102M [00:00<00:00, 107MB/s]  \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1oCjM_VWXrAVToRwuUFgW1bupBpmc7Rwx\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet101_quant.tflite\n",
      "100%|██████████| 45.4M/45.4M [00:00<00:00, 90.4MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1yImWscZUsOANKwV15WIN77o7Q2Yrkc14\n",
      "From (redirected): https://drive.google.com/uc?id=1yImWscZUsOANKwV15WIN77o7Q2Yrkc14&confirm=t&uuid=cce1cb01-ccf0-4676-9986-88e02038cdfe\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet101.tflite\n",
      "100%|██████████| 178M/178M [00:03<00:00, 55.6MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1824S3uNOro0WBlccpflEJhXzGR8k7L5w\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet152_quant.tflite\n",
      "100%|██████████| 61.4M/61.4M [00:01<00:00, 45.1MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1JwfKL79O75XiamF5iEqGkUSt9LYygwS3\n",
      "From (redirected): https://drive.google.com/uc?id=1JwfKL79O75XiamF5iEqGkUSt9LYygwS3&confirm=t&uuid=df591b60-1fa2-4e7e-8549-5ba4a458cfe1\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet152.tflite\n",
      "100%|██████████| 241M/241M [00:04<00:00, 55.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1m-RI9IV3vIuiHJ-BoHc4XnPn0fewJzGs\n",
      "From (redirected): https://drive.google.com/uc?id=1m-RI9IV3vIuiHJ-BoHc4XnPn0fewJzGs&confirm=t&uuid=5a52194f-4d64-4eb2-9626-7540b4446263\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/VGG16_quant.tflite\n",
      "100%|██████████| 138M/138M [00:04<00:00, 28.0MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1XywqHW8wmqkfTw6cjo7xlnYaTlr9AbwE\n",
      "From (redirected): https://drive.google.com/uc?id=1XywqHW8wmqkfTw6cjo7xlnYaTlr9AbwE&confirm=t&uuid=d843579c-79a6-414b-a7c3-d711e334cd2b\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/VGG16.tflite\n",
      "100%|██████████| 553M/553M [00:04<00:00, 120MB/s]  \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Jo-SqyPZvCG8p2Cvpq1tNPhd3LavQ24_\n",
      "From (redirected): https://drive.google.com/uc?id=1Jo-SqyPZvCG8p2Cvpq1tNPhd3LavQ24_&confirm=t&uuid=ee00bd8f-4136-46e2-be33-f1695ea87bfb\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/VGG19_quant.tflite\n",
      "100%|██████████| 144M/144M [00:02<00:00, 53.5MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1sEfBpOdcw-LQAl24Y0SMH4fVWoyCCBki\n",
      "From (redirected): https://drive.google.com/uc?id=1sEfBpOdcw-LQAl24Y0SMH4fVWoyCCBki&confirm=t&uuid=a2f4354e-ff3d-48ac-a322-bec0c73f9cf4\n",
      "To: /home/cc/DeepLearning-EdgeComputing/tflite_models/VGG19.tflite\n",
      "100%|██████████| 575M/575M [00:05<00:00, 105MB/s]  \n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/cc/DeepLearning-EdgeComputing/tflite_models/InceptionV3_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/InceptionV3.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet50_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet50.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet101_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet101.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet152_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/ResNet152.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/VGG16_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/VGG16.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/VGG19_quant.tflite',\n",
       " '/home/cc/DeepLearning-EdgeComputing/tflite_models/VGG19.tflite']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "import gdown\n",
    "gdown.download_folder('https://drive.google.com/drive/folders/1OcJ9ceYg6ZWFJ4QMR0zznsw0KVeHPa4h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkKMH6CMCv1z"
   },
   "source": [
    "You can verify that the models were correctly loaded by listing the files in the /root/tflite_models directory. Note that there should be two tflite files for each model: an original and a quantized version. The size of the quantized models should be significantly smaller than the size of their corresponding original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-RyqChjIDEUe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cc/DeepLearning-EdgeComputing/tflite_models:\n",
      "total 2152992\n",
      "-rw-rw-r-- 1 cc cc  95324856 Jul 21 15:40 InceptionV3.tflite\n",
      "-rw-rw-r-- 1 cc cc  24138200 Jul 21 15:43 InceptionV3_quant.tflite\n",
      "-rw-rw-r-- 1 cc cc  16903376 Jul 21 15:43 MobileNet.tflite\n",
      "-rw-rw-r-- 1 cc cc   4423744 Jul 21 15:43 MobileNet_quant.tflite\n",
      "-rw-rw-r-- 1 cc cc 178055132 Jul 21 15:25 ResNet101.tflite\n",
      "-rw-rw-r-- 1 cc cc  45360928 Jul 21 15:42 ResNet101_quant.tflite\n",
      "-rw-rw-r-- 1 cc cc 240570616 Jul 21 15:16 ResNet152.tflite\n",
      "-rw-rw-r-- 1 cc cc  61361208 Jul 21 15:41 ResNet152_quant.tflite\n",
      "-rw-rw-r-- 1 cc cc 102157452 Jul 21 15:39 ResNet50.tflite\n",
      "-rw-rw-r-- 1 cc cc  25968784 Jul 21 15:43 ResNet50_quant.tflite\n",
      "-rw-rw-r-- 1 cc cc 553439904 Jul 21 15:05 VGG16.tflite\n",
      "-rw-rw-r-- 1 cc cc 138458672 Jul 21 15:37 VGG16_quant.tflite\n",
      "-rw-rw-r-- 1 cc cc 574680200 Jul 21 14:41 VGG19.tflite\n",
      "-rw-rw-r-- 1 cc cc 143789152 Jul 21 15:31 VGG19_quant.tflite\n"
     ]
    }
   ],
   "source": [
    "!ls -lR /home/cc/DeepLearning-EdgeComputing/tflite_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWcYnbyPX0SR"
   },
   "source": [
    "Next, we download the TFlite benchmark which we will use to measure inference times and memory footprint. More details about the benchmark can be found on the [tensorflow website](https://www.tensorflow.org/lite/performance/measurement). Note that the benchmark is specific to the architecture type (such as x86 or ARM), and the appropriate benchmark binary must be downloaded. Below, the benchmark is loaded for an x86-64 type architecture.\n",
    "\n",
    "The benchmark is downloaded to the /root/benchmark folder, and its permissions are then updated to allow it to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "b1ZDxygKnKy8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-25 11:55:50--  https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.115.207, 64.233.180.207, 172.253.63.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.115.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6205384 (5.9M) [application/octet-stream]\n",
      "Saving to: ‘/home/cc/DeepLearning-EdgeComputing/benchmark/linux_x86-64_benchmark_model’\n",
      "\n",
      "linux_x86-64_benchm 100%[===================>]   5.92M  28.3MB/s    in 0.2s    \n",
      "\n",
      "2024-07-25 11:55:50 (28.3 MB/s) - ‘/home/cc/DeepLearning-EdgeComputing/benchmark/linux_x86-64_benchmark_model’ saved [6205384/6205384]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/cc/DeepLearning-EdgeComputing/benchmark\n",
    "!wget https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model -P /home/cc/DeepLearning-EdgeComputing/benchmark\n",
    "!chmod +x /home/cc/DeepLearning-EdgeComputing/benchmark/linux_x86-64_benchmark_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4yYd2m0CJ1L"
   },
   "source": [
    "Let's run the benchmark on the MobileNet_quant model and note the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gxwkgn7ECZv7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: STARTING!\n",
      "INFO: Log parameter values verbosely: [0]\n",
      "INFO: Num threads: [1]\n",
      "INFO: Graph: [/home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet_quant.tflite]\n",
      "INFO: Signature to run: []\n",
      "INFO: #threads used for CPU inference: [1]\n",
      "INFO: Loaded model /home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet_quant.tflite\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: The input model file size (MB): 4.42374\n",
      "INFO: Initialized session in 44.168ms.\n",
      "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=60 first=9810 curr=8562 min=8267 max=9810 avg=8401.87 std=215\n",
      "\n",
      "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
      "INFO: count=119 first=8363 curr=8315 min=8262 max=8739 avg=8354.76 std=77\n",
      "\n",
      "INFO: Inference timings in us: Init: 44168, First inference: 9810, Warmup (avg): 8401.87, Inference (avg): 8354.76\n",
      "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
      "INFO: Memory footprint delta from the start of the tool (MB): init=0 overall=0\n"
     ]
    }
   ],
   "source": [
    "!/home/cc/DeepLearning-EdgeComputing/benchmark/linux_x86-64_benchmark_model \\\n",
    "      --graph=/home/cc/DeepLearning-EdgeComputing/tflite_models/MobileNet_quant.tflite \\\n",
    "      --num_threads=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMpKVIzvX3Ym"
   },
   "source": [
    "Since the result of the benchmark is reported as text on the console, we can define a parsing function to extract the data. The parsing function takes the output of the benchmark as an input and adds the results to a dictionary of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2dXGB-Dv0mxg"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_benchmark_output(output, results):\n",
    "    \"\"\"\n",
    "    Parse benchmark output to extract model initialization times, inference timings, and memory footprint.\n",
    "    \"\"\"\n",
    "\n",
    "    # Regular expressions to match the required information\n",
    "    init_time_patterns = [\n",
    "        re.compile(r'INFO: Initialized session in (\\d+.\\d+)ms.'),\n",
    "        re.compile(r'INFO: Initialized session in (\\d+)ms.')\n",
    "    ]\n",
    "    inference_patterns = [\n",
    "        re.compile(r'INFO: Inference timings in us: Init: (\\d+), First inference: (\\d+), Warmup \\(avg\\): (\\d+.\\d+), Inference \\(avg\\): (\\d+.\\d+)'),\n",
    "        re.compile(r'INFO: Inference timings in us: Init: (\\d+), First inference: (\\d+), Warmup \\(avg\\): (\\d+), Inference \\(avg\\): (\\d+)'),\n",
    "        re.compile(r'INFO: Inference timings in us: Init: (\\d+), First inference: (\\d+), Warmup \\(avg\\): ([\\d.e+]+), Inference \\(avg\\): (\\d+)')\n",
    "    ]\n",
    "    memory_pattern = re.compile(r'INFO: Memory footprint delta from the start of the tool \\(MB\\): init=(\\d+.\\d+) overall=(\\d+.\\d+)')\n",
    "\n",
    "    for line in output.split('\\n'):\n",
    "        # Match the initialization time\n",
    "        for pattern in init_time_patterns:\n",
    "            init_match = pattern.search(line)\n",
    "            if init_match:\n",
    "                results['Init Time (ms)'].append(float(init_match.group(1)))\n",
    "                break\n",
    "\n",
    "        # Match the inference timings\n",
    "        for pattern in inference_patterns:\n",
    "            inference_match = pattern.search(line)\n",
    "            if inference_match:\n",
    "                results[\"Init Inference (ms)\"].append(int(inference_match.group(1))/1000)\n",
    "                results[\"First Inference (ms)\"].append(int(inference_match.group(2))/1000)\n",
    "                results[\"Warmup Inference (ms)\"].append(float(inference_match.group(3))/1000)\n",
    "                results[\"Avg Inference (ms)\"].append(float(inference_match.group(4))/1000)\n",
    "                break\n",
    "\n",
    "        # Match the memory footprint\n",
    "        memory_match = memory_pattern.search(line)\n",
    "        if memory_match:\n",
    "            results['Memory Init (MB)'].append(float(memory_match.group(1)))\n",
    "            results['Memory Overall (MB)'].append(float(memory_match.group(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezfpt0IGGlWU"
   },
   "source": [
    "Next, we can define a Pandas Dataframe to store our results. Since we will be repeatedly running the benchmark to estimate the standard deviation of results as well, for each metric, we will define two columns - one for the mean and the other for the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "P5DH1Ki5G2nF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define model types (rows)\n",
    "rows = []\n",
    "for model in modelNames:\n",
    "  rows.append(model)\n",
    "  rows.append(model + \"_quant\")\n",
    "\n",
    "# Define features (columns)\n",
    "cols = []\n",
    "features = [\"Init Time (ms)\", \"Init Inference (ms)\", \"First Inference (ms)\", \"Warmup Inference (ms)\", \"Avg Inference (ms)\", \"Memory Init (MB)\", \"Memory Overall (MB)\"]\n",
    "for feature in features:\n",
    "  cols.append(feature)\n",
    "  cols.append(feature + \"_sd\")\n",
    "\n",
    "# Create an empty DataFrame\n",
    "finalResult = pd.DataFrame(index=rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1BWO_62YAY4"
   },
   "source": [
    "Finally, run the benchmark repeatedly and average the results. For each model, we repeatedly run the benchmark, and parse the output from the benchmark. After `n` trials, the mean and standard deviation of the metrics is added to the `finalResult` dataframe defined in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvngpXpxlpvO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet_quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3_quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50_quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet101_quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet152_quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "\n",
    "n = 10 #the number of times the benchmark is called for each model\n",
    "\n",
    "for modelName in rows:\n",
    "  print(modelName)\n",
    "  modelResults = defaultdict(list)\n",
    "  for i in range(n):\n",
    "    outputOriginal = subprocess.check_output(\"/home/cc/DeepLearning-EdgeComputing/benchmark/linux_x86-64_benchmark_model \\\n",
    "      --graph=/home/cc/DeepLearning-EdgeComputing/tflite_models/\" + modelName +\".tflite\"+\" \\\n",
    "      --num_threads=1\", shell=True)\n",
    "    outputOriginal = outputOriginal.decode('utf-8')\n",
    "    output = parse_benchmark_output(outputOriginal, modelResults)\n",
    "\n",
    "  for feature in features:\n",
    "    finalResult.loc[modelName, feature] = mean(modelResults[feature])\n",
    "    finalResult.loc[modelName, feature + \"_sd\"] = stdev(modelResults[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlGDdZ72av1e"
   },
   "source": [
    "Let's have a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1y1FR0REYNCD"
   },
   "outputs": [],
   "source": [
    "print(finalResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86e8u7c0RI6J"
   },
   "source": [
    "Finally, we can generate plots of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a directory to store the results:/home/cc/DeepLearning-EdgeComputing/notebooks/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /home/cc/DeepLearning-EdgeComputing/notebooks/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzVfeDYXRW1c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for feature in features:\n",
    "    means_orig = finalResult.loc[modelNames, feature].values\n",
    "    errors_orig = finalResult.loc[modelNames, feature + \"_sd\"].values\n",
    "    means_quant = finalResult.loc[[model + \"_quant\" for model in modelNames], feature].values\n",
    "    errors_quant = finalResult.loc[[model + \"_quant\" for model in modelNames], feature + \"_sd\"].values\n",
    "\n",
    "\n",
    "    n_groups = len(modelNames)\n",
    "    index = np.arange(n_groups)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bar_width = 0.35\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, means_orig, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     yerr=errors_orig,\n",
    "                     label='Original')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, means_quant, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     yerr=errors_quant,\n",
    "                     label='Quantized')\n",
    "\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel(feature)\n",
    "    plt.title(f'Bar Chart for {feature}')\n",
    "    plt.xticks(index + bar_width / 2, modelNames, rotation=45)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/home/cc/DeepLearning-EdgeComputing/notebooks/results/{feature}.png')\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmWjEmg9k9L8E37YqPA4Id",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
