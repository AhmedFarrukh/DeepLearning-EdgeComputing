{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrHAcnydEebFqWM724HkD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedFarrukh/DeepLearning-EdgeComputing/blob/main/Reproducing_Paper_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an effort to reproduce the findings of the paper, \"To Compress, or Not to Compress: Characterizing Deep Learning Model Compression for Embedded Inference\", 7 popular convolutional neural network models will be trained, quantized and then tested for accuracy and inference time."
      ],
      "metadata": {
        "id": "qrF-tC2TOA5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "77dSfcJtPaU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToA8HeyjN7qQ"
      },
      "outputs": [],
      "source": [
        "modelNames = [\"MobileNet\", \"ResNet50\", \"ResNet101\", \"InceptionV3\", \"VGG16\", \"VGG19\", \"ResNet152\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for modelName in modelNames:\n",
        "  model = tf.keras.applications.MobileNet(\n",
        "    weights='imagenet'\n",
        "  )\n",
        "\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  tflite_model_quant = converter.convert()\n",
        "\n",
        "  tflite_models_dir = pathlib.Path(\"/tmp/tflite_models/\")\n",
        "  tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  # Save the unquantized/float model:\n",
        "  tflite_model_file = tflite_models_dir/(modelName+\".tflite\")\n",
        "  tflite_model_file.write_bytes(tflite_model)\n",
        "  # Save the quantized model:\n",
        "  tflite_model_quant_file = tflite_models_dir/(modelName+\"_quant.tflite\")\n",
        "  tflite_model_quant_file.write_bytes(tflite_model_quant)\n"
      ],
      "metadata": {
        "id": "CwkPgqOwPbhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cc3a46-e517-4068-b3af-dce24af28796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17225924/17225924 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /tmp/benchmark\n",
        "!wget https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model -P /tmp/benchmark\n",
        "!chmod +x /tmp/benchmark/linux_x86-64_benchmark_model\n",
        "!touch /tmp/benchmark/results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2GwmlnjSr19",
        "outputId": "1308c8c6-c9fb-4e0d-b9e7-0940f9efef3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-28 11:11:46--  https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.207, 108.177.96.207, 108.177.119.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6237672 (5.9M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/benchmark/linux_x86-64_benchmark_model’\n",
            "\n",
            "linux_x86-64_benchm 100%[===================>]   5.95M  8.01MB/s    in 0.7s    \n",
            "\n",
            "2024-06-28 11:11:47 (8.01 MB/s) - ‘/tmp/benchmark/linux_x86-64_benchmark_model’ saved [6237672/6237672]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for modelName in modelNames:\n",
        "  os.system(\"echo \\\"\" + modelName + \"; Original\\n\\\" >> /tmp/benchmark/results\" )\n",
        "\n",
        "  os.system(\"/tmp/benchmark/linux_x86-64_benchmark_model \\\n",
        "    --graph=/tmp/tflite_models/\" + modelName +\".tflite\"+\" \\\n",
        "    --num_threads=1 >> /tmp/benchmark/results\")\n",
        "\n",
        "  os.system(\"echo \\\"\\n\" + modelName + \"; Quantized\\n\\\" >> /tmp/benchmark/results\" )\n",
        "\n",
        "  os.system(\"/tmp/benchmark/linux_x86-64_benchmark_model \\\n",
        "    --graph=/tmp/tflite_models/\" + modelName +\"_quant.tflite\"+\" \\\n",
        "    --num_threads=1 >> /tmp/benchmark/results\")\n",
        "\n",
        "  os.system(\"echo \\\"\" + \"\\n\\n\\\" >> /tmp/benchmark/results\" )\n",
        "\n",
        "f = open(\"/tmp/benchmark/results\", \"r\")\n",
        "print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShC99aBGSspA",
        "outputId": "e6fb6969-8baa-4cfc-a589-8600583ea64a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/MobileNet.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/MobileNet.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 130.151ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=24494 curr=23378 min=23340 max=26421 avg=24077.7 std=750\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=23758 curr=23574 min=23221 max=36097 avg=24795.7 std=2277\n",
            "\n",
            "INFO: Inference timings in us: Init: 130151, First inference: 24494, Warmup (avg): 24077.7, Inference (avg): 24795.7\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.4023 overall=44.3828\n",
            "\n",
            "MobileNet; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/MobileNet_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/MobileNet_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 81.375ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=32224 curr=29870 min=29200 max=35582 avg=30197.5 std=1590\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29184 curr=30012 min=29048 max=41267 avg=30315.2 std=2182\n",
            "\n",
            "INFO: Inference timings in us: Init: 81375, First inference: 32224, Warmup (avg): 30197.5, Inference (avg): 30315.2\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.2773 overall=22.4688\n",
            "\n",
            "\n",
            "\n",
            "ResNet50; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet50.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet50.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 24.108ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=19 first=28477 curr=24602 min=23738 max=41480 avg=27166.8 std=5579\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=24582 curr=23643 min=23083 max=40053 avg=24686.7 std=2739\n",
            "\n",
            "INFO: Inference timings in us: Init: 24108, First inference: 28477, Warmup (avg): 27166.8, Inference (avg): 24686.7\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.0312 overall=43.7539\n",
            "\n",
            "ResNet50; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet50_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet50_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 18.789ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=35079 curr=29104 min=28996 max=35079 avg=29871.9 std=1461\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=28982 curr=29134 min=28842 max=37987 avg=29914.3 std=1352\n",
            "\n",
            "INFO: Inference timings in us: Init: 18789, First inference: 35079, Warmup (avg): 29871.9, Inference (avg): 29914.3\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.6992 overall=22.6328\n",
            "\n",
            "\n",
            "\n",
            "ResNet101; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet101.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet101.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 40.216ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=25040 curr=24560 min=23372 max=26278 avg=24187.9 std=708\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=23541 curr=42357 min=23323 max=51206 avg=32445.5 std=7680\n",
            "\n",
            "INFO: Inference timings in us: Init: 40216, First inference: 25040, Warmup (avg): 24187.9, Inference (avg): 32445.5\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.1484 overall=43.8711\n",
            "\n",
            "ResNet101; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet101_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet101_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 26.381ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=11 first=51929 curr=47796 min=45850 max=51929 avg=48497.8 std=1537\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=47650 curr=29938 min=28847 max=54245 avg=43851.1 std=7819\n",
            "\n",
            "INFO: Inference timings in us: Init: 26381, First inference: 51929, Warmup (avg): 48497.8, Inference (avg): 43851.1\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.4727 overall=22.4648\n",
            "\n",
            "\n",
            "\n",
            "InceptionV3; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/InceptionV3.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/InceptionV3.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 21.575ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=20 first=30428 curr=23445 min=23445 max=36276 avg=25088.7 std=2969\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=24668 curr=23675 min=23011 max=33052 avg=24115.8 std=1542\n",
            "\n",
            "INFO: Inference timings in us: Init: 21575, First inference: 30428, Warmup (avg): 25088.7, Inference (avg): 24115.8\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.1836 overall=43.9062\n",
            "\n",
            "InceptionV3; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/InceptionV3_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/InceptionV3_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 16.054ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=31199 curr=29007 min=28835 max=32324 avg=29755.4 std=950\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=30852 curr=29565 min=28797 max=40812 avg=29989.9 std=2240\n",
            "\n",
            "INFO: Inference timings in us: Init: 16054, First inference: 31199, Warmup (avg): 29755.4, Inference (avg): 29989.9\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.5859 overall=22.5781\n",
            "\n",
            "\n",
            "\n",
            "VGG16; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG16.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG16.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 30.051ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=24285 curr=23270 min=23270 max=26135 avg=24131.8 std=777\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=24910 curr=23810 min=23218 max=35305 avg=24417.3 std=2286\n",
            "\n",
            "INFO: Inference timings in us: Init: 30051, First inference: 24285, Warmup (avg): 24131.8, Inference (avg): 24417.3\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.3086 overall=43.9727\n",
            "\n",
            "VGG16; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG16_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG16_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 18.95ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=31639 curr=31290 min=28817 max=31639 avg=29766.3 std=844\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29467 curr=29692 min=28842 max=40525 avg=30124.3 std=2215\n",
            "\n",
            "INFO: Inference timings in us: Init: 18950, First inference: 31639, Warmup (avg): 29766.3, Inference (avg): 30124.3\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.5234 overall=22.3398\n",
            "\n",
            "\n",
            "\n",
            "VGG19; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG19.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG19.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 34.047ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=24377 curr=23437 min=23367 max=25981 avg=24098.7 std=708\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=23940 curr=23213 min=22979 max=31303 avg=24212.3 std=1359\n",
            "\n",
            "INFO: Inference timings in us: Init: 34047, First inference: 24377, Warmup (avg): 24098.7, Inference (avg): 24212.3\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.1484 overall=43.8125\n",
            "\n",
            "VGG19; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG19_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG19_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 18.534ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=13 first=31174 curr=47628 min=29013 max=49596 avg=41861.3 std=7566\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=49845 curr=46981 min=45411 max=66633 avg=49308.3 std=3234\n",
            "\n",
            "INFO: Inference timings in us: Init: 18534, First inference: 31174, Warmup (avg): 41861.3, Inference (avg): 49308.3\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.6211 overall=22.4961\n",
            "\n",
            "\n",
            "\n",
            "ResNet152; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet152.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet152.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 39.696ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=13 first=38142 curr=38449 min=36914 max=52112 avg=39321.8 std=3969\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=38377 curr=23811 min=23181 max=39629 avg=26175.8 std=5043\n",
            "\n",
            "INFO: Inference timings in us: Init: 39696, First inference: 38142, Warmup (avg): 39321.8, Inference (avg): 26175.8\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=41.918 overall=43.6406\n",
            "\n",
            "ResNet152; Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet152_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet152_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 18.971ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=31320 curr=29273 min=29018 max=36448 avg=30213.4 std=1959\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=31109 curr=29369 min=29164 max=38371 avg=30209.6 std=1509\n",
            "\n",
            "INFO: Inference timings in us: Init: 18971, First inference: 31320, Warmup (avg): 30213.4, Inference (avg): 30209.6\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.5547 overall=22.4883\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}