{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrHAcnydEebFqWM724HkD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedFarrukh/DeepLearning-EdgeComputing/blob/main/Copy_of_Reproducing_Paper_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an effort to reproduce the findings of the paper, \"To Compress, or Not to Compress: Characterizing Deep Learning Model Compression for Embedded Inference\", 7 popular convolutional neural network models will be trained, quantized and then tested for accuracy and inference time."
      ],
      "metadata": {
        "id": "qrF-tC2TOA5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "77dSfcJtPaU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToA8HeyjN7qQ"
      },
      "outputs": [],
      "source": [
        "modelNames = [\"MobileNet\", \"ResNet50\", \"ResNet101\", \"InceptionV3\", \"VGG16\", \"VGG19\", \"ResNet152\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for modelName in modelNames:\n",
        "  model = tf.keras.applications.MobileNet(\n",
        "    weights='imagenet'\n",
        "  )\n",
        "\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  tflite_model_quant = converter.convert()\n",
        "\n",
        "  tflite_models_dir = pathlib.Path(\"/tmp/tflite_models/\")\n",
        "  tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  # Save the unquantized/float model:\n",
        "  tflite_model_file = tflite_models_dir/(modelName+\".tflite\")\n",
        "  tflite_model_file.write_bytes(tflite_model)\n",
        "  # Save the quantized model:\n",
        "  tflite_model_quant_file = tflite_models_dir/(modelName+\"_quant.tflite\")\n",
        "  tflite_model_quant_file.write_bytes(tflite_model_quant)\n"
      ],
      "metadata": {
        "id": "CwkPgqOwPbhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cc3a46-e517-4068-b3af-dce24af28796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17225924/17225924 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /tmp/benchmark\n",
        "!wget https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model -P /tmp/benchmark\n",
        "!chmod +x /tmp/benchmark/linux_x86-64_benchmark_model\n",
        "!touch /tmp/benchmark/results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2GwmlnjSr19",
        "outputId": "1308c8c6-c9fb-4e0d-b9e7-0940f9efef3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-28 11:11:46--  https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.207, 108.177.96.207, 108.177.119.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6237672 (5.9M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/benchmark/linux_x86-64_benchmark_model’\n",
            "\n",
            "linux_x86-64_benchm 100%[===================>]   5.95M  8.01MB/s    in 0.7s    \n",
            "\n",
            "2024-06-28 11:11:47 (8.01 MB/s) - ‘/tmp/benchmark/linux_x86-64_benchmark_model’ saved [6237672/6237672]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for modelName in modelNames:\n",
        "  os.system(\"echo \\\"\" + modelName + \"; Original\\n\\\" >> /tmp/benchmark/results\" )\n",
        "\n",
        "  os.system(\"/tmp/benchmark/linux_x86-64_benchmark_model \\\n",
        "    --graph=/tmp/tflite_models/\" + modelName +\".tflite\"+\" \\\n",
        "    --num_threads=1 >> /tmp/benchmark/results\")\n",
        "\n",
        "  os.system(\"echo \\\"\\n\" + modelName + \"; Quantized\\n\\\" >> /tmp/benchmark/results\" )\n",
        "\n",
        "  os.system(\"/tmp/benchmark/linux_x86-64_benchmark_model \\\n",
        "    --graph=/tmp/tflite_models/\" + modelName +\"_quant.tflite\"+\" \\\n",
        "    --num_threads=1 >> /tmp/benchmark/results\")\n",
        "\n",
        "  os.system(\"echo \\\"\" + \"\\n\\n\\\" >> /tmp/benchmark/results\" )\n",
        "\n",
        "f = open(\"/tmp/benchmark/results\", \"r\")\n",
        "print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShC99aBGSspA",
        "outputId": "67c58af9-d138-46f2-c0ec-d5cc8430dd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/MobileNet.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/MobileNet.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 28.059ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=26857 curr=23422 min=22913 max=29693 avg=24552.9 std=2165\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=23691 curr=23147 min=22377 max=32141 avg=23559.8 std=1550\n",
            "\n",
            "INFO: Inference timings in us: Init: 28059, First inference: 26857, Warmup (avg): 24552.9, Inference (avg): 23559.8\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.2617 overall=44.1836\n",
            "MobileNet ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/MobileNet_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/MobileNet_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 15.597ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=16 first=48018 curr=29015 min=28728 max=48018 avg=31651.6 std=4571\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29197 curr=47887 min=28770 max=59997 avg=42352.2 std=9250\n",
            "\n",
            "INFO: Inference timings in us: Init: 15597, First inference: 48018, Warmup (avg): 31651.6, Inference (avg): 42352.2\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.6797 overall=22.6133\n",
            "\n",
            "\n",
            "\n",
            "ResNet50; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet50.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet50.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 28.966ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=13 first=39352 curr=42377 min=35569 max=47283 avg=39824.8 std=3045\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=38260 curr=22808 min=22691 max=50806 avg=34464 std=7044\n",
            "\n",
            "INFO: Inference timings in us: Init: 28966, First inference: 39352, Warmup (avg): 39824.8, Inference (avg): 34464\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.3242 overall=43.9883\n",
            "ResNet50 ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet50_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet50_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 15.29ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=35179 curr=29407 min=28842 max=37386 avg=30945.8 std=2437\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29235 curr=29082 min=28849 max=38357 avg=29728.8 std=1475\n",
            "\n",
            "INFO: Inference timings in us: Init: 15290, First inference: 35179, Warmup (avg): 30945.8, Inference (avg): 29728.8\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.3203 overall=22.1953\n",
            "\n",
            "\n",
            "\n",
            "ResNet101; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet101.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet101.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 20.324ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=24653 curr=22906 min=22906 max=34785 avg=24399.5 std=2513\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=23092 curr=23358 min=22500 max=34280 avg=23574 std=1914\n",
            "\n",
            "INFO: Inference timings in us: Init: 20324, First inference: 24653, Warmup (avg): 24399.5, Inference (avg): 23574\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=41.9375 overall=43.6016\n",
            "ResNet101 ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet101_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet101_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 15.541ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=32247 curr=31090 min=28921 max=36890 avg=30389.6 std=2064\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29479 curr=29641 min=28688 max=41699 avg=29622.6 std=1881\n",
            "\n",
            "INFO: Inference timings in us: Init: 15541, First inference: 32247, Warmup (avg): 30389.6, Inference (avg): 29622.6\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.3281 overall=22.1445\n",
            "\n",
            "\n",
            "\n",
            "InceptionV3; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/InceptionV3.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/InceptionV3.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 20.155ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=23212 curr=23175 min=22496 max=34113 avg=23856.3 std=2512\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=22910 curr=23507 min=22509 max=35652 avg=23551.5 std=1983\n",
            "\n",
            "INFO: Inference timings in us: Init: 20155, First inference: 23212, Warmup (avg): 23856.3, Inference (avg): 23551.5\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.1836 overall=43.9062\n",
            "InceptionV3 ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/InceptionV3_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/InceptionV3_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 15.206ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=31364 curr=29347 min=28728 max=31364 avg=29384.1 std=591\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29221 curr=28807 min=28807 max=40917 avg=30134.5 std=2252\n",
            "\n",
            "INFO: Inference timings in us: Init: 15206, First inference: 31364, Warmup (avg): 29384.1, Inference (avg): 30134.5\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.4336 overall=22.4258\n",
            "\n",
            "\n",
            "\n",
            "VGG16; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG16.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG16.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 20.158ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=14 first=26097 curr=37616 min=26097 max=39037 avg=37232.4 std=3133\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=37547 curr=36472 min=35944 max=42602 avg=38374.1 std=1366\n",
            "\n",
            "INFO: Inference timings in us: Init: 20158, First inference: 26097, Warmup (avg): 37232.4, Inference (avg): 38374.1\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.1914 overall=43.8555\n",
            "VGG16 ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG16_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG16_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 24.069ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=11 first=48069 curr=46574 min=46574 max=54154 avg=48676 std=2283\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=48115 curr=28820 min=28619 max=50487 avg=34317.8 std=7810\n",
            "\n",
            "INFO: Inference timings in us: Init: 24069, First inference: 48069, Warmup (avg): 48676, Inference (avg): 34317.8\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.5273 overall=22.4023\n",
            "\n",
            "\n",
            "\n",
            "VGG19; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG19.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG19.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 20.392ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=23567 curr=22850 min=22838 max=35752 avg=24013 std=2705\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=23462 curr=22979 min=22952 max=34243 avg=23921 std=1715\n",
            "\n",
            "INFO: Inference timings in us: Init: 20392, First inference: 23567, Warmup (avg): 24013, Inference (avg): 23921\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.1875 overall=44.1094\n",
            "VGG19 ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/VGG19_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/VGG19_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 15.418ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=31309 curr=29605 min=28879 max=37613 avg=30140 std=2031\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29036 curr=29307 min=28681 max=40159 avg=29652.7 std=1799\n",
            "\n",
            "INFO: Inference timings in us: Init: 15418, First inference: 31309, Warmup (avg): 30140, Inference (avg): 29652.7\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.3711 overall=22.3633\n",
            "\n",
            "\n",
            "\n",
            "ResNet152; Original\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet152.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet152.tflite\n",
            "INFO: The input model file size (MB): 16.9034\n",
            "INFO: Initialized session in 20.603ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=21 first=24027 curr=23437 min=23178 max=29656 avg=24302 std=1841\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=24345 curr=23102 min=22650 max=30957 avg=23843.2 std=1464\n",
            "\n",
            "INFO: Inference timings in us: Init: 20603, First inference: 24027, Warmup (avg): 24302, Inference (avg): 23843.2\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=42.3789 overall=44.2422\n",
            "ResNet152 ;Quantized\n",
            "\n",
            "INFO: STARTING!\n",
            "INFO: Log parameter values verbosely: [0]\n",
            "INFO: Num threads: [1]\n",
            "INFO: Graph: [/tmp/tflite_models/ResNet152_quant.tflite]\n",
            "INFO: Signature to run: []\n",
            "INFO: #threads used for CPU inference: [1]\n",
            "INFO: Loaded model /tmp/tflite_models/ResNet152_quant.tflite\n",
            "INFO: The input model file size (MB): 4.42374\n",
            "INFO: Initialized session in 15.537ms.\n",
            "INFO: Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=17 first=30895 curr=30080 min=28704 max=31237 avg=29574.6 std=686\n",
            "\n",
            "INFO: Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "INFO: count=50 first=29338 curr=28789 min=28715 max=36959 avg=30135.6 std=1978\n",
            "\n",
            "INFO: Inference timings in us: Init: 15537, First inference: 30895, Warmup (avg): 29574.6, Inference (avg): 30135.6\n",
            "INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "INFO: Memory footprint delta from the start of the tool (MB): init=17.8164 overall=22.75\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}